{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-code_env_cc_fraud",
      "display_name": "Python (env code_env_cc_fraud)",
      "language": "python"
    },
    "creator": "admin",
    "createdOn": 1655309908880,
    "tags": [],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Building a tool to retrieve all libraries used by all code env on the whole instance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. Libraries importation"
      ]
    },
    {
      "execution_count": 17,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nfrom dataiku import pandasutils as pdu\nimport pandas as pd"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2. Creating a client from inside DSS\nTo work with the API, a connection needs to be established with DSS, by creating a DSSClient object. Once the connection is established, the DSSClient object serves as the entry point to the other calls.\n\nThe Python client can be used from inside DSS. In that case:\n\n- It’s preinstalled, you don’t need to do anything\n\n- You don’t need to provide any API key, as the API client will automatically inherit connection credentials from the current context"
      ]
    },
    {
      "execution_count": 18,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "client \u003d dataiku.api_client()\n# client is now a DSSClient and can perform all authorized actions."
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. Listing all code envs setup on the DSS instance with their libraries"
      ]
    },
    {
      "execution_count": 62,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get the list of all the code env on the DSS instance\n# Every code env is described by a dictionary from which we want to extract code env names\nlist_code_env_full \u003d client.list_code_envs()"
      ],
      "outputs": []
    },
    {
      "execution_count": 64,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Filter the code env names and types\nlist_code_env \u003d []\nfor code_env in list_code_env_full: \n    temp_code_env \u003d {}\n    for key, value in code_env.items():\n        if (key \u003d\u003d \u0027envName\u0027) or (key \u003d\u003d \u0027envLang\u0027):\n            temp_code_env[key] \u003d value\n    list_code_env.append(temp_code_env)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get the libraries of each code env\nfor code_env in list_code_env:\n    code_env_handle \u003d client.get_code_env(code_env[\u0027envLang\u0027], code_env[\u0027envName\u0027])\n    code_env.get_definition()[\u0027actualPackageList\u0027].split(\u0027\\n\u0027)"
      ],
      "outputs": []
    },
    {
      "execution_count": 68,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sel \u003d client.get_code_env(\u0027PYTHON\u0027, \u0027INTERNAL_image_classification_v1\u0027)"
      ],
      "outputs": []
    },
    {
      "execution_count": 69,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sel.get_definition()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 69,
          "data": {
            "text/plain": "{\u0027desc\u0027: {\u0027pythonInterpreter\u0027: \u0027PYTHON36\u0027,\n  \u0027installCorePackages\u0027: True,\n  \u0027corePackagesSet\u0027: \u0027PANDAS10\u0027,\n  \u0027installJupyterSupport\u0027: True,\n  \u0027dockerImageResources\u0027: \u0027COPY\u0027,\n  \u0027updateResourcesApiNode\u0027: False,\n  \u0027conda\u0027: False,\n  \u0027creationTag\u0027: {\u0027versionNumber\u0027: 0,\n   \u0027lastModifiedBy\u0027: {\u0027login\u0027: \u0027admin\u0027},\n   \u0027lastModifiedOn\u0027: 1655106707065},\n  \u0027versionTag\u0027: {\u0027versionNumber\u0027: 0,\n   \u0027lastModifiedBy\u0027: {\u0027login\u0027: \u0027admin\u0027},\n   \u0027lastModifiedOn\u0027: 1655106707065},\n  \u0027deploymentMode\u0027: \u0027DSS_INTERNAL\u0027,\n  \u0027envSettings\u0027: {\u0027inheritGlobalSettings\u0027: True,\n   \u0027condaInstallExtraOptions\u0027: [],\n   \u0027condaCreateExtraOptions\u0027: [],\n   \u0027pipInstallExtraOptions\u0027: [],\n   \u0027virtualenvCreateExtraOptions\u0027: [],\n   \u0027cranMirrorURL\u0027: \u0027https://cloud.r-project.org\u0027},\n  \u0027owner\u0027: \u0027admin\u0027,\n  \u0027usableByAll\u0027: True,\n  \u0027permissions\u0027: [],\n  \u0027allContainerConfs\u0027: False,\n  \u0027containerConfs\u0027: [],\n  \u0027allSparkKubernetesConfs\u0027: False,\n  \u0027sparkKubernetesConfs\u0027: []},\n \u0027info\u0027: {},\n \u0027resourcesInitScript\u0027: \u0027from dataiku.code_env_resources import clear_all_env_vars\\nfrom dataiku.code_env_resources import set_env_path\\nfrom dataiku.code_env_resources import set_env_var\\nfrom dataiku.code_env_resources import grant_permissions\\n\\n# Clears all environment variables defined by previously run script\\nclear_all_env_vars()\\n\\n# Set image classification version environment variable\\nset_env_var(\"DKU_DEEP_HUB_IMAGE_CLASSIFICATION_VERSION\", \"1\")\\n\\n# Set PyTorch cache directory\\nset_env_path(\"TORCH_HOME\", \"pytorch\")\\n\\n# Import PyTorch\\nimport torchvision\\n\\n# Download pretrained model\\ntorchvision.models.efficientnet_b0(pretrained\u003dTrue)\\ntorchvision.models.efficientnet_b4(pretrained\u003dTrue)\\ntorchvision.models.efficientnet_b7(pretrained\u003dTrue)\\n\\n# Grant filesystem permissions to pytorch pretrained models\\ngrant_permissions(\"pytorch\")\\n\u0027,\n \u0027deploymentMode\u0027: \u0027DSS_INTERNAL\u0027,\n \u0027owner\u0027: \u0027admin\u0027,\n \u0027usableByAll\u0027: True,\n \u0027envLang\u0027: \u0027PYTHON\u0027,\n \u0027envName\u0027: \u0027INTERNAL_image_classification_v1\u0027,\n \u0027path\u0027: \u0027/Users/camillecochener/Library/DataikuV10/dss_design/code-envs/python/INTERNAL_image_classification_v1\u0027,\n \u0027kernelSpecName\u0027: \u0027py-dku-venv-internal_image_classification_v1\u0027,\n \u0027unknownKernelSpecStatus\u0027: False,\n \u0027canUpdateCodeEnv\u0027: True,\n \u0027canManageUsersCodeEnv\u0027: True,\n \u0027permissions\u0027: [],\n \u0027mandatoryPackageList\u0027: \u0027\\npandas\u003e\u003d1.0,\u003c1.1\\npython-dateutil\u003d\u003d2.8.1\\npytz\u003d\u003d2020.5\\nrequests\u003c3\\n\\ndecorator\u003d\u003d4.4.2\\nipykernel\u003d\u003d4.8.2\\nipython_genutils\u003d\u003d0.2.0\\njupyter_client\u003d\u003d5.2.4\\njupyter_core\u003d\u003d4.4.0\\npexpect\u003d\u003d4.8.0\\npickleshare\u003d\u003d0.7.5\\nptyprocess\u003d\u003d0.7.0\\npyzmq\u003d\u003d18.0.2\\nsimplegeneric\u003d\u003d0.8.1\\ntornado\u003d\u003d5.1.1\\ntraitlets\u003d\u003d4.3.3\\n\u0027,\n \u0027mandatoryCondaEnvironment\u0027: \u0027\u0027,\n \u0027specPackageList\u0027: \u0027albumentations\u003d\u003d1.1.0\\ncloudpickle\u003e\u003d1.3,\u003c1.6\\nflask\u003e\u003d1.0,\u003c1.1\\njedi\u003d\u003d0.17.2\\njinja2\u003e\u003d2.10,\u003c2.11\\njoblib\u003d\u003d1.1.0\\nMarkupSafe\u003c2.1.0\\nPillow\u003d\u003d8.4.0\\nscikit-learn\u003e\u003d0.20,\u003c0.21\\nscipy\u003e\u003d1.2,\u003c1.3\\nstatsmodels\u003e\u003d0.10,\u003c0.11\\ntorch\u003d\u003d1.10.1\\ntorchvision\u003d\u003d0.11.2\u0027,\n \u0027specCondaEnvironment\u0027: \u0027\u0027,\n \u0027actualPackageList\u0027: \u0027albumentations\u003d\u003d1.1.0\\nappnope\u003d\u003d0.1.3\\nbackcall\u003d\u003d0.2.0\\ncertifi\u003d\u003d2022.5.18.1\\ncharset-normalizer\u003d\u003d2.0.12\\nclick\u003d\u003d8.0.4\\ncloudpickle\u003d\u003d1.5.0\\ncycler\u003d\u003d0.11.0\\ndataclasses\u003d\u003d0.8\\ndecorator\u003d\u003d4.4.2\\nFlask\u003d\u003d1.0.4\\nidna\u003d\u003d3.3\\nimageio\u003d\u003d2.15.0\\nimportlib-metadata\u003d\u003d4.8.3\\nipykernel\u003d\u003d4.8.2\\nipython\u003d\u003d7.16.3\\nipython-genutils\u003d\u003d0.2.0\\nitsdangerous\u003d\u003d2.0.1\\njedi\u003d\u003d0.17.2\\nJinja2\u003d\u003d2.10.3\\njoblib\u003d\u003d1.1.0\\njupyter-client\u003d\u003d5.2.4\\njupyter-core\u003d\u003d4.4.0\\nkiwisolver\u003d\u003d1.3.1\\nMarkupSafe\u003d\u003d2.0.1\\nmatplotlib\u003d\u003d3.3.4\\nnetworkx\u003d\u003d2.5.1\\nnumpy\u003d\u003d1.19.5\\nopencv-python-headless\u003d\u003d4.6.0.66\\npandas\u003d\u003d1.0.5\\nparso\u003d\u003d0.7.1\\npatsy\u003d\u003d0.5.2\\npexpect\u003d\u003d4.8.0\\npickleshare\u003d\u003d0.7.5\\nPillow\u003d\u003d8.4.0\\nprompt-toolkit\u003d\u003d3.0.29\\nptyprocess\u003d\u003d0.7.0\\nPygments\u003d\u003d2.12.0\\npyparsing\u003d\u003d3.0.9\\npython-dateutil\u003d\u003d2.8.1\\npytz\u003d\u003d2020.5\\nPyWavelets\u003d\u003d1.1.1\\nPyYAML\u003d\u003d6.0\\npyzmq\u003d\u003d18.0.2\\nqudida\u003d\u003d0.0.4\\nrequests\u003d\u003d2.27.1\\nscikit-image\u003d\u003d0.17.2\\nscikit-learn\u003d\u003d0.20.4\\nscipy\u003d\u003d1.2.3\\nsimplegeneric\u003d\u003d0.8.1\\nsix\u003d\u003d1.16.0\\nstatsmodels\u003d\u003d0.10.2\\ntifffile\u003d\u003d2020.9.3\\ntorch\u003d\u003d1.10.1\\ntorchvision\u003d\u003d0.11.2\\ntornado\u003d\u003d5.1.1\\ntraitlets\u003d\u003d4.3.3\\ntyping_extensions\u003d\u003d4.1.1\\nurllib3\u003d\u003d1.26.9\\nwcwidth\u003d\u003d0.2.5\\nWerkzeug\u003d\u003d2.0.3\\nzipp\u003d\u003d3.6.0\\n\u0027,\n \u0027actualCondaEnvironment\u0027: \u0027\u0027,\n \u0027allContainerConfs\u0027: False,\n \u0027containerConfs\u0027: [],\n \u0027allSparkKubernetesConfs\u0027: False,\n \u0027sparkKubernetesConfs\u0027: []}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "execution_count": 19,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "project \u003d client.get_project(\"DSPIPELINEFRAUD\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 26,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "project_code_env \u003d project.get_settings().get_raw()[\u0027settings\u0027][\u0027codeEnvs\u0027][\u0027python\u0027][\u0027envName\u0027]"
      ],
      "outputs": []
    },
    {
      "execution_count": 54,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "project_code_env"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 54,
          "data": {
            "text/plain": "\u0027code_env_cc_fraud\u0027"
          },
          "metadata": {}
        }
      ]
    },
    {
      "execution_count": 55,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "project_recipes \u003d project.list_recipes()\nproject_python_recipe \u003d [recipe for recipe in project_recipes if recipe[\u0027type\u0027] \u003d\u003d \u0027python\u0027] "
      ],
      "outputs": []
    },
    {
      "execution_count": 56,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "python_recipe_code_env \u003d [python_recipe[\u0027params\u0027][\u0027envSelection\u0027][\u0027envName\u0027] for python_recipe in project_python_recipe if python_recipe[\u0027params\u0027][\u0027envSelection\u0027][\u0027envMode\u0027] \u003d\u003d \u0027EXPLICIT_ENV\u0027]"
      ],
      "outputs": []
    },
    {
      "execution_count": 57,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "code_env \u003d client.get_code_env(\u0027PYTHON\u0027, project_code_env)"
      ],
      "outputs": []
    },
    {
      "execution_count": 58,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "code_env.get_definition()[\u0027actualPackageList\u0027].split(\u0027\\n\u0027)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 58,
          "data": {
            "text/plain": "[\u0027appnope\u003d\u003d0.1.3\u0027,\n \u0027backcall\u003d\u003d0.2.0\u0027,\n \u0027certifi\u003d\u003d2022.5.18.1\u0027,\n \u0027charset-normalizer\u003d\u003d2.0.12\u0027,\n \u0027decorator\u003d\u003d4.4.2\u0027,\n \u0027idna\u003d\u003d3.3\u0027,\n \u0027ipykernel\u003d\u003d4.8.2\u0027,\n \u0027ipython\u003d\u003d7.16.3\u0027,\n \u0027ipython-genutils\u003d\u003d0.2.0\u0027,\n \u0027jedi\u003d\u003d0.17.2\u0027,\n \u0027jupyter-client\u003d\u003d5.2.4\u0027,\n \u0027jupyter-core\u003d\u003d4.4.0\u0027,\n \u0027numpy\u003d\u003d1.19.5\u0027,\n \u0027pandas\u003d\u003d1.0.5\u0027,\n \u0027parso\u003d\u003d0.7.1\u0027,\n \u0027pexpect\u003d\u003d4.8.0\u0027,\n \u0027pickleshare\u003d\u003d0.7.5\u0027,\n \u0027prompt-toolkit\u003d\u003d3.0.29\u0027,\n \u0027ptyprocess\u003d\u003d0.7.0\u0027,\n \u0027Pygments\u003d\u003d2.12.0\u0027,\n \u0027python-dateutil\u003d\u003d2.8.1\u0027,\n \u0027pytz\u003d\u003d2020.5\u0027,\n \u0027pyzmq\u003d\u003d18.0.2\u0027,\n \u0027requests\u003d\u003d2.27.1\u0027,\n \u0027simplegeneric\u003d\u003d0.8.1\u0027,\n \u0027six\u003d\u003d1.16.0\u0027,\n \u0027tornado\u003d\u003d5.1.1\u0027,\n \u0027traitlets\u003d\u003d4.3.3\u0027,\n \u0027urllib3\u003d\u003d1.26.9\u0027,\n \u0027wcwidth\u003d\u003d0.2.5\u0027,\n \u0027\u0027]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# list_jupyter_notebooks\n# list_recipes\n# list_running_notebooks"
      ],
      "outputs": []
    }
  ]
}